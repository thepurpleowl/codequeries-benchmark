{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Setup\n",
    "\n",
    "```\n",
    "pip install openai \n",
    "pip install datasets\n",
    "pip install tiktoken\n",
    "```"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "571ad2e7cec8e9b3"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Basic use of CodeQueries\n",
    "\n",
    "Single data instance looks like this:\n",
    "```\n",
    "{'query_name': 'Unused import',\n",
    " 'code_file_path': 'rcbops/glance-buildpackage/glance/tests/unit/test_db.py',\n",
    " 'context_block': {'content': '# vim: tabstop=4 shiftwidth=4 softtabstop=4\\n\\n# Copyright 2010-2011 OpenStack, LLC\\ ...',\n",
    "                    'metadata': 'root',\n",
    "                    'header': \"['module', '___EOS___']\",\n",
    "                    'index': 0},\n",
    " 'answer_spans': [{'span': 'from glance.common import context',\n",
    "                   'start_line': 19,\n",
    "                   'start_column': 0,\n",
    "                   'end_line': 19,\n",
    "                   'end_column': 33}\n",
    "                 ],\n",
    " 'supporting_fact_spans': [],\n",
    " 'example_type': 1,\n",
    " 'single_hop': False,\n",
    " 'subtokenized_input_sequence': ['[CLS]_', 'Un', 'used_', 'import_', '[SEP]_', 'module_', '\\\\u\\\\u\\\\uEOS\\\\u\\\\u\\\\u_', '#', ' ', 'vim', ':', ...],\n",
    " 'label_sequence': [4, 4, 4, 4, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...],\n",
    " 'relevance_label': 1\n",
    "}\n",
    "```"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e9d2f5efda6c5bb"
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total queries in CodeQueries: 52\n",
      "Few queries are :- \n",
      "  1. Unnecessary 'else' clause in loop\n",
      "  2. Conflicting attributes in base classes\n",
      "  3. Unnecessary delete statement in function\n",
      "  4. Modification of parameter with default\n",
      "  5. Constant in conditional expression or statement\n"
     ]
    }
   ],
   "source": [
    "import datasets\n",
    "\n",
    "ds = datasets.load_dataset(\"thepurpleowl/codequeries\", \"twostep\", split=datasets.Split.TEST, trust_remote_code=True)\n",
    "\n",
    "all_queries = set(ds['query_name'])\n",
    "print(f\"Total queries in CodeQueries: {len(all_queries)}\")\n",
    "few_queries = '\\n'.join([('  ' + str(idx+1) + '. ' + query) for idx, query in enumerate(list(all_queries)[:5])])\n",
    "print(f\"Few queries are :- \\n{few_queries}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-10T07:45:08.179320Z",
     "start_time": "2024-02-10T07:45:02.647995Z"
    }
   },
   "id": "7aab926999f77a90"
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: Inconsistent equality and hashing\n",
      "File path: phaethon/scapy/scapy/fields.py\n"
     ]
    },
    {
     "data": {
      "text/plain": "Filter:   0%|          | 0/4058 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8047b4644c7045a6a4ca2bf282e2d478"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total blocks for query: 'Inconsistent equality and hashing' and file: 'phaethon/scapy/scapy/fields.py' are - 226\n",
      "Total relevant blocks: 5\n",
      "Answer spans:\n",
      " No Answer Spans\n",
      "Supporting fact spans:\n",
      " No Answer Spans\n",
      "-----------------------\n",
      "Relevant code context:\n",
      "-----------------------\n",
      " class Emph:\n",
      "    fld = b\"\"\n",
      "    def __init__(self, fld):\n",
      "        self.fld = fld\n",
      "    def __getattr__(self, attr):\n",
      "        return getattr(self.fld,attr)\n",
      "    def __hash__(self):\n",
      "        return hash(self.fld)\n",
      "    def __eq__(self, other):\n",
      "        return self.fld == other\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "query_dataset = ds.filter(lambda example: example['query_name'] == \"Inconsistent equality and hashing\")\n",
    "data_instance = query_dataset[random.randint(0, query_dataset.shape[0])]\n",
    "print(f\"Query: {data_instance['query_name']}\\nFile path: {data_instance['code_file_path']}\")\n",
    "\n",
    "def get_sanitized_content(ctxt_blocks):\n",
    "    \"\"\"You can add your logic of cleaning data here. For now, we are just removing newlines.\"\"\"\n",
    "    context_blocks = \"\"\n",
    "    for ctxt_block in ctxt_blocks:\n",
    "        newline_removed_content = (\"\\n\".join(line \n",
    "                                             for line in ctxt_block['content'].split('\\n')\n",
    "                                             if line))\n",
    "        context_blocks += newline_removed_content\n",
    "        context_blocks += '\\n'\n",
    "    return context_blocks\n",
    "\n",
    "query_file_pair_dataset = query_dataset.filter(lambda example: example[\"query_name\"]==data_instance['query_name'] and example['code_file_path']==data_instance['code_file_path'])\n",
    "print(f\"Total blocks for query: '{data_instance['query_name']}' and file: '{data_instance['code_file_path']}' are - {query_file_pair_dataset.shape[0]}\")\n",
    "\n",
    "relevant_code_blocks = []\n",
    "answer_spans = []\n",
    "supporting_fact_spans = []\n",
    "for i, datum in enumerate(query_file_pair_dataset):\n",
    "    if datum['relevance_label'] == 1:\n",
    "        relevant_code_blocks.append(datum['context_block'])\n",
    "        \n",
    "    if i == 0:\n",
    "        for span in datum['answer_spans']:\n",
    "            answer_spans.append(span['span'])\n",
    "        for span in datum['supporting_fact_spans']:\n",
    "            supporting_fact_spans.append(span['span'])\n",
    "    else:\n",
    "        for span in datum['answer_spans']:\n",
    "            assert span['span'] in answer_spans\n",
    "        for span in datum['supporting_fact_spans']:\n",
    "            assert span['span'] in supporting_fact_spans\n",
    "\n",
    "code_context = get_sanitized_content([instance['context_block'] for instance in query_file_pair_dataset])\n",
    "relevant_code_context = get_sanitized_content(relevant_code_blocks)\n",
    "ans_spans = '\\n'.join([('  ' + str(idx+1) + '. ' + span) for idx, span in enumerate(answer_spans)])\n",
    "sf_spans = '\\n'.join([('  ' + str(idx+1) + '. ' + span) for idx, span in enumerate(supporting_fact_spans)])\n",
    "print(f\"Total relevant blocks: {len(relevant_code_blocks)}\")\n",
    "print(f\"Answer spans:\\n {ans_spans if ans_spans else 'No Answer Spans'}\")\n",
    "print(f\"Supporting fact spans:\\n {sf_spans if sf_spans else 'No Answer Spans'}\")\n",
    "print(f\"-----------------------\\nRelevant code context:\\n-----------------------\\n {relevant_code_context}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-10T07:45:49.575577Z",
     "start_time": "2024-02-10T07:45:49.129764Z"
    }
   },
   "id": "89467bbfd43836ad"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Prompt with LLM"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3b5a22404b99e27c"
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def __eq__(self, other):\n",
      "    return self.fld == other\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import tiktoken\n",
    "\n",
    "\n",
    "MODEL = \"gpt-3.5-turbo\"\n",
    "def count_tokens(input_str: str, model_name: str = MODEL) -> int:\n",
    "    encoding = tiktoken.encoding_for_model(model_name)\n",
    "    num_tokens = len(encoding.encode(input_str))\n",
    "    return num_tokens\n",
    "\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=\"OPENAI_API_KEY\",\n",
    ")\n",
    "\n",
    "# You can get description and examples from the query examples from - https://codeql.github.com/codeql-query-help/python/\n",
    "description = \"Defining equality for a class without also defining hashability (or vice-versa) violates the object model.\"\n",
    "system_message = (f\"You are an expert software developer. Please help identify the results of evaluating the CodeQL query titled {data_instance['query_name']} on a code snippet.\"\n",
    "                  f\"The results should be given as code spans or fragments (if any) from the code snippet. The description of the CodeQL query { data_instance['query_name'] } is - {description}\"\n",
    "                  f\"If there are spans that match the query description, print them out one per line. \\n\")\n",
    "code_prompt = (f\"Code snippet\\n\"\n",
    "                  f\"```python\\n\"\n",
    "                  f\"{ relevant_code_context }\\n\"\n",
    "                  f\"```\\n\"\n",
    "                  f\"Code span(s)\\n\"\n",
    "                  f\"```python\")\n",
    "# Code contexts can exceed 4096 tokens, so you can split them into multiple messages\n",
    "if  count_tokens(code_prompt) > 4096:\n",
    "    code_prompt = code_prompt[:3000]\n",
    "                            \n",
    "input_messages= [\n",
    "    {\"role\": \"user\",\"content\": system_message},\n",
    "    {\"role\": \"user\", \"content\": code_prompt}\n",
    "]\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages=input_messages,\n",
    "    model=MODEL,\n",
    "    temperature=0.8\n",
    ")\n",
    "print(chat_completion.choices[0].message.content)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-10T07:45:50.813993Z",
     "start_time": "2024-02-10T07:45:49.878110Z"
    }
   },
   "id": "5acc4659430a7a89"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-10T07:21:00.964471Z"
    }
   },
   "id": "1c6399036f1af689"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
